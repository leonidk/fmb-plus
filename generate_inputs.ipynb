{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob\n",
    "import pathlib\n",
    "\n",
    "import numpy as np\n",
    "import skimage\n",
    "import skimage.io as sio\n",
    "import skimage.transform as strans\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import transforms3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process CO3D data in data2 for a certain class\n",
    "data_dir = '.'\n",
    "type_f = 'teddybear' # hydrant, plant\n",
    "idx_num = 1 # which idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "viables = [_ for _ in sorted(os.listdir(os.path.join(data_dir,type_f))) if os.path.isdir(os.path.join(data_dir,type_f,_)) and len(os.path.join(data_dir,type_f,_).split('_')) == 3]\n",
    "co3d_seq = viables[idx_num]\n",
    "output_folder = type_f+'_'+co3d_seq\n",
    "co3d_seq_folder = os.path.join(data_dir,type_f,co3d_seq)\n",
    "co3d_seq,co3d_seq_folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requirements\n",
    "\n",
    "[unimatch](https://github.com/autonomousvision/unimatch) for generating optical flow\n",
    "\n",
    "\n",
    "[XMem](https://github.com/hkchengrex/XMem) for propogating the first mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder = co3d_seq_folder\n",
    "input_folder = os.path.join(base_folder,'images')\n",
    "output_folder = os.path.join('rvid','{}_{}'.format(type_f,co3d_seq))\n",
    "\n",
    "target_size = 125000\n",
    "gmflow_path = '../unimatch/'\n",
    "xmem_path = '../XMem/'\n",
    "\n",
    "frame1_mask = os.path.join(base_folder,'masks','frame000001.png')\n",
    "\n",
    "imgs_folder = os.path.join(output_folder,'JPEGImages','video1')\n",
    "silh_folder = os.path.join(output_folder,'Annotations','video1')\n",
    "flow_folder = os.path.join(output_folder,'Flow','video1')\n",
    "\n",
    "for gen_folder in [output_folder,imgs_folder,silh_folder,flow_folder]:\n",
    "    if not os.path.exists(gen_folder):\n",
    "        #import shutil\n",
    "        #shutil.rmtree(gen_folder)\n",
    "        os.makedirs(gen_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_files = sorted(glob.glob(os.path.join(input_folder,'*.jpg')) + glob.glob(os.path.join(input_folder,'*.png')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PYo,PXo = sio.imread(in_files[0]).shape[:2]\n",
    "init_scale = np.prod([PYo,PXo])\n",
    "scales = {}\n",
    "for i in range(10):\n",
    "    scale = 2**i\n",
    "    scales[scale] = init_scale/(scale**2)\n",
    "scale_to_use = sorted([(abs(np.log(v/target_size)),k) for k,v in scales.items() ])[0][1]\n",
    "PY,PX = int(round(PYo/scale_to_use)),int(round(PXo/scale_to_use))\n",
    "scale_to_use,PY,PX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_inputs = []\n",
    "file_map = {}\n",
    "for idx,file in enumerate(in_files):\n",
    "    name = pathlib.Path(file).parts[-1]\n",
    "    #if not os.path.exists(os.path.join(imgs_folder,name)):\n",
    "    img = sio.imread(file)\n",
    "    valid_inputs.append(img.sum() != 0)\n",
    "    new_name = 'frame{:06d}.jpg'.format(sum(valid_inputs))\n",
    "    if valid_inputs[-1] == False:\n",
    "        continue\n",
    "    #print(new_name)\n",
    "    file_map[idx] = sum(valid_inputs)\n",
    "    simg = strans.resize(img,(PY,PX))\n",
    "    sio.imsave(os.path.join(imgs_folder,new_name),skimage.img_as_ubyte(simg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(os.path.join(*(base_folder.split('/')[:-1] + ['frame_annotations.jgz'])),compression={'method':'gzip'})\n",
    "df2 = df[df.sequence_name == int(co3d_seq.replace('_',''))]\n",
    "fls = []\n",
    "pps = []\n",
    "sizes = []\n",
    "assert(len(df2) == len(valid_inputs))\n",
    "for i,row in enumerate(df2.sort_values('frame_number').itertuples()):\n",
    "    fn, imgd, maskd, view = row[2],row[4],row[6],row[7]\n",
    "    if not valid_inputs[i]:\n",
    "        continue\n",
    "    fl = np.array(view['focal_length'])\n",
    "    pp = np.array(view['principal_point'])\n",
    "    sizeA = list(row[4]['size'])\n",
    "\n",
    "    if 'intrinsics_format' in view and view['intrinsics_format'] == 'ndc_isotropic':\n",
    "        half_image_size_wh_orig = np.array(list(reversed(sizeA))) / 2.0\n",
    "        rescale = half_image_size_wh_orig.min()\n",
    "        # principal point and focal length in pixels\n",
    "        principal_point_px = half_image_size_wh_orig - pp * rescale\n",
    "        focal_length_px = fl * rescale\n",
    "    else:\n",
    "        half_image_size_wh_orig = np.array(list(reversed(sizeA))) / 2.0\n",
    "        # principal point and focal length in pixels\n",
    "        principal_point_px = (\n",
    "            -1.0 * (pp - 1.0) * half_image_size_wh_orig\n",
    "        )\n",
    "        focal_length_px = fl * half_image_size_wh_orig\n",
    "\n",
    "    fls.append(focal_length_px)\n",
    "    pps.append(principal_point_px)\n",
    "\n",
    "    sizes.append(sizeA)\n",
    "assert(np.array(sizes).std(0).sum() == 0) # same sizes\n",
    "pp = np.array(pps).mean(0)\n",
    "fl = np.array(fls).mean(0).mean()\n",
    "meanpp = (np.array([pp[1],pp[0]])/np.array(sizes).mean(0)).mean() \n",
    "assert(abs(meanpp - 0.5) < 1e-3) # basically center of frame\n",
    "fl = fl/scale_to_use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(valid_inputs),df2.shape,len(in_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poses = []\n",
    "depths = []\n",
    "import skimage.io as sio\n",
    "import skimage.transform as sktrans\n",
    "\n",
    "for i,row in enumerate(df2.sort_values('frame_number').itertuples()):\n",
    "    fn, imgd, maskd, view = row[2],row[4],row[6],row[7]\n",
    "    depthd = row[5]\n",
    "    if not valid_inputs[i]:\n",
    "        continue\n",
    "    maskd = maskd['path'][maskd['path'].index(co3d_seq):]\n",
    "    imgd = imgd['path'][imgd['path'].index(co3d_seq):]\n",
    "    \n",
    "    Rmat = np.array(view['R'])\n",
    "    Tvec = np.array(view['T'])\n",
    "    Tvec = -Rmat @ Tvec\n",
    "    q = transforms3d.quaternions.mat2quat(Rmat.T)\n",
    "    poses.append(list(q) + list(Tvec))\n",
    "    \n",
    "    depth_r = sio.imread(os.path.join(data_dir,type_f,depthd['path'][depthd['path'].index(co3d_seq):]))#.astype(float)\n",
    "    depth_m = sio.imread(os.path.join(data_dir,type_f,depthd['mask_path'][depthd['mask_path'].index(co3d_seq):])).astype(float)\n",
    "    \n",
    "    depth_r_s = depth_r.shape\n",
    "    depth_r = depthd['scale_adjustment']*np.frombuffer(depth_r,dtype=np.float16).astype(np.float32).reshape(depth_r_s)\n",
    "\n",
    "    valid_d = (depth_r > 0)\n",
    "    depth_r[~valid_d] = np.nan\n",
    "    depth_r = sktrans.resize(depth_r,(PY,PX),anti_aliasing=False,order=0)\n",
    "    depths.append(depth_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gzip\n",
    "import trimesh\n",
    "with gzip.open(os.path.join(output_folder,'pose_depth.pkl.gz'), \"wb\") as f:\n",
    "    out_dict = {'fl':fl,'poses':poses,'depths':depths}\n",
    "    ply_path = os.path.join(co3d_seq_folder,'pointcloud.ply')\n",
    "    if os.path.exists(ply_path):\n",
    "        out_dict['mesh'] = trimesh.load(ply_path)\n",
    "    pickle.dump(out_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gm_flow_cmd = \"\"\"CUDA_VISIBLE_DEVICES=\"0\" python {} \\\n",
    "--inference_dir {} \\\n",
    "--output_path {} \\\n",
    "--pred_bidir_flow \\\n",
    "--save_flo_flow \\\n",
    "--resume {} {}\n",
    "\"\"\"\n",
    "alt_cmd =  '--inference_size {} {}'.format(PX*2,PY*2) if target_size < 1e5 else ''\n",
    "gm_flow_cmd_f = gm_flow_cmd.format(os.path.join(gmflow_path,'main_flow.py'),imgs_folder,flow_folder,os.path.join(gmflow_path,'pretrained','gmflow-scale1-mixdata-train320x576-4c3a6e9a.pth'),alt_cmd)\n",
    "print(gm_flow_cmd_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(glob.glob(os.path.join(flow_folder,'*.flo'))) != (len(in_files)*2-2):\n",
    "    os.system(gm_flow_cmd_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgM = sio.imread(frame1_mask)\n",
    "simgM = skimage.img_as_ubyte(strans.resize(imgM,(PY,PX)) >0.5)\n",
    "sio.imsave(os.path.join(silh_folder,pathlib.Path(in_files[0]).parts[-1].replace('.jpg','.png')),simgM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmem_output = os.path.join(output_folder,'masks')\n",
    "xmem_cmd = 'python {} --model {} --dataset G --generic_path {} --output {}'.format(os.path.join(xmem_path,'eval.py'),os.path.join(xmem_path,'saves','XMem.pth'),output_folder,xmem_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system(xmem_cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmem_cmd"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
