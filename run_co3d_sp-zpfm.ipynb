{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run CO3D Sequence (zero parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from utils_opt import readFlow\n",
    "\n",
    "import skimage.io as sio\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = 'rvid/teddybear_34_1479_4753/'\n",
    "co3d_seq = os.path.split(dataset_dir.rstrip('/').lstrip('/'))[-1]\n",
    "output_folder = os.path.join('tmp_out_zpfm',co3d_seq)\n",
    "NUM_MIXTURE = 40\n",
    "shape_scale = 1.8\n",
    "c_scale = 4.5\n",
    "f_scale = 210\n",
    "rand_sphere_size = 55\n",
    "cov_scale = 1.2e-2\n",
    "weight_scale = 1.1\n",
    "LR_RATE = 0.08\n",
    "Nepoch = 10\n",
    "batch_size = 50000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import pickle\n",
    "\n",
    "\n",
    "with gzip.open(os.path.join(dataset_dir,'pose_depth.pkl.gz'),'rb') as fp:\n",
    "    depth_and_pose = pickle.load(fp)\n",
    "    \n",
    "true_depths = depth_and_pose['depths']\n",
    "fl = depth_and_pose['fl']\n",
    "poses = np.array(depth_and_pose['poses'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks_folder = os.path.join(dataset_dir,'masks','video1')\n",
    "in_files = sorted(glob.glob(masks_folder + '/*.png'))\n",
    "\n",
    "masks = []\n",
    "for img_loc in in_files:\n",
    "    mask = sio.imread(img_loc).astype(np.float32)\n",
    "    mask = (mask > 0).astype(np.float32)\n",
    "    masks.append(mask)\n",
    "masks = np.array(masks)\n",
    "PY,PX = mask.shape\n",
    "image_size = (PY,PX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks_folder = os.path.join(dataset_dir,'JPEGImages','video1')\n",
    "in_files = sorted(glob.glob(masks_folder + '/*.jpg'))\n",
    "\n",
    "images = []\n",
    "for img_loc in in_files:\n",
    "    img = sio.imread(img_loc).astype(np.float32)\n",
    "    images.append(img)\n",
    "images = np.array(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fwd_flows = []\n",
    "bwd_flows = []\n",
    "\n",
    "flow_fol = os.path.join(dataset_dir,'Flow','video1','*.flo')\n",
    "\n",
    "flow_files = sorted(glob.glob(flow_fol))\n",
    "\n",
    "for flfile in flow_files:\n",
    "    new_flow = readFlow(flfile)\n",
    "    if PY > PX:\n",
    "        new_flow = np.stack([new_flow[:,:,1],new_flow[:,:,0]],axis=2)\n",
    "    if 'bwd' in flfile:\n",
    "        bwd_flows.append(new_flow)\n",
    "    else:\n",
    "        fwd_flows.append(new_flow)\n",
    "\n",
    "\n",
    "# last flow has no fowards\n",
    "fwd_flows = fwd_flows + [new_flow*0]\n",
    "# first flow has no backwards\n",
    "bwd_flows = [new_flow*0] + bwd_flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'mesh' in depth_and_pose:\n",
    "    pt_cld = depth_and_pose['mesh'].vertices\n",
    "    import sklearn.mixture as mixture\n",
    "\n",
    "    idx2 = np.arange(pt_cld.shape[0])\n",
    "    np.random.shuffle(idx2)\n",
    "    clf = mixture.GaussianMixture(40)\n",
    "    clf.fit(pt_cld[idx2[:10000]])\n",
    "\n",
    "    pt_cld_shape_scale = float(pt_cld.std(0).mean())*3 \n",
    "    center = pt_cld.mean(0)\n",
    "else:\n",
    "    pt_cld_shape_scale = 3.0\n",
    "    center = np.zeros(3,dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCALE_MUL_FACTOR = shape_scale/pt_cld_shape_scale\n",
    "# gradients can be sensitive to scale. here we solve on scale = 2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"] = \"false\"\n",
    "\n",
    "import jax\n",
    "#jax.config.update('jax_platform_name', 'cpu')\n",
    "\n",
    "import jax.numpy as jnp\n",
    "import zpfm_render\n",
    "\n",
    "render_jit = jax.jit(zpfm_render.render_func_idx_quattrans)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_shape = (PY,PX)\n",
    "min_size_idx = np.argmin(img_shape)\n",
    "min_size = img_shape[min_size_idx]\n",
    "max_size = img_shape[1-min_size_idx]\n",
    "invF = 0.5*min_size/fl\n",
    "min_dim = np.linspace(-1,1,min_size)\n",
    "aspect = max_size/min_size\n",
    "max_dim = np.linspace(-aspect,aspect,max_size)\n",
    "grid = [-max_dim,-min_dim,1,0] if min_size_idx == 0 else [-min_dim,-max_dim,1,0]\n",
    "pixel_list = np.transpose(np.squeeze(np.meshgrid(*grid,indexing='ij')),(2,1,0))\n",
    "\n",
    "print(pixel_list.shape,img_shape)\n",
    "pixel_list = pixel_list.reshape((-1,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poses = jnp.array(poses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import image_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random init settings\n",
    "rand_mean = center+pt_cld_shape_scale*np.random.multivariate_normal(mean=[0,0,0],cov=cov_scale*np.identity(3),size=NUM_MIXTURE)\n",
    "rand_weight_log = jnp.log(weight_scale*np.ones(NUM_MIXTURE)/NUM_MIXTURE)\n",
    "rand_prec = jnp.array([np.identity(3)*rand_sphere_size/pt_cld_shape_scale for _ in range(NUM_MIXTURE)])\n",
    "rand_color = jnp.array(np.random.randn(NUM_MIXTURE,3))\n",
    "\n",
    "init_alphas = []\n",
    "for i in range(len(poses)):\n",
    "    pixel_list[:,3] = i\n",
    "    res_img,est_alpha,_,_ = render_jit(rand_mean,rand_prec,rand_weight_log,pixel_list,invF,poses)\n",
    "\n",
    "    res_imgA = np.array(res_img)\n",
    "    res_imgA[est_alpha < 0.5] = np.nan\n",
    "    init_alphas.append(est_alpha.reshape((PY,PX)))\n",
    "image_grid(init_alphas,6,6,rgb=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_ray_set = []\n",
    "for i in range(len(poses)):\n",
    "    pixel_list[:,3] = i\n",
    "\n",
    "    total_ray_set.append(pixel_list.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_rays = jnp.vstack(total_ray_set)\n",
    "# scaled into ray coord space, vectorized flows\n",
    "fwv_flow = jnp.array(np.array(fwd_flows).reshape((-1,2)))/(min_size/2)\n",
    "bwv_flow = jnp.array(np.array(bwd_flows).reshape((-1,2)))/(min_size/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "render_jit_ray = jax.jit(zpfm_render.render_func_rays)\n",
    "last_img_size = np.prod(img_shape)\n",
    "v_idx = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params,camera_rays,invF,poses,true_alpha,true_fwd,true_bwd,true_color):\n",
    "    CLIP_ALPHA = 1e-6\n",
    "    means,prec,weights_log,colors = params\n",
    "    est_depth, est_alpha, est_norm, est_w,flowp,flowm = zpfm_render.render_func_idx_quattrans_flow(means,prec,weights_log,camera_rays,invF,poses)\n",
    "    est_w = est_w.T\n",
    "    est_w = est_w/jnp.maximum(est_w.sum(axis=1,keepdims=True),1e-7)\n",
    "    \n",
    "    est_color = est_w @ (jnp.tanh(colors)*0.5+0.5)\n",
    "    est_alpha = jnp.clip(est_alpha,CLIP_ALPHA,1-CLIP_ALPHA)\n",
    "    mask_loss = - ((true_alpha * jnp.log(est_alpha)) + (1-true_alpha)*jnp.log(1-est_alpha))\n",
    "    pad_alpha = (true_alpha)[:,None]\n",
    "    flow1 = jnp.abs(pad_alpha*true_fwd-pad_alpha*jnp.nan_to_num(flowp))\n",
    "    flow2 = jnp.abs(pad_alpha*true_bwd-pad_alpha*jnp.nan_to_num(flowm))\n",
    "    cdiff = jnp.abs( (true_color-est_color)*true_alpha[:,None] )\n",
    "    return mask_loss.mean() + c_scale*cdiff.mean() + f_scale*(flow1.mean() + flow2.mean())  #+ 0\n",
    "grad_render3 = jax.value_and_grad(objective)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCALE_MUL_FACTOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optax\n",
    "from tqdm.notebook import tqdm\n",
    "from util import DegradeLR\n",
    "\n",
    "vecM = jnp.array([1,1,1,1,SCALE_MUL_FACTOR,SCALE_MUL_FACTOR,SCALE_MUL_FACTOR])[None]\n",
    "\n",
    "train_size = all_rays.shape[0]\n",
    "Niter_epoch = int(round(train_size/batch_size))\n",
    "\n",
    "def irc(x): return int(round(x))\n",
    "\n",
    "# babysit learning rates\n",
    "adjust_lr = DegradeLR(LR_RATE,0.5,irc(Niter_epoch*0.25),irc(Niter_epoch*0.1),-1e-4)\n",
    "\n",
    "optimizer = optax.adam(adjust_lr.step_func)\n",
    "\n",
    "tmp = [rand_mean,rand_prec,rand_weight_log,rand_color]\n",
    "#tmp = [means,prec,weights_log]\n",
    "\n",
    "opt_state = optimizer.init(tmp)\n",
    "\n",
    "all_sils = jnp.hstack([_.ravel() for _ in masks]).astype(jnp.float32)\n",
    "all_colors = jnp.hstack([_.ravel()/255.0 for _ in images]).astype(jnp.float32).reshape((-1,3))\n",
    "all_colors = all_colors**(1/2.2)\n",
    "\n",
    "losses = []\n",
    "opt_configs = []\n",
    "outer_loop = tqdm(range(Nepoch), desc=\" epoch\", position=0)\n",
    "\n",
    "rand_idx = np.arange(train_size)\n",
    "params = tmp\n",
    "def inner_iter(j_idx,rand_idx_local,opt_state,p):\n",
    "    idx = jax.lax.dynamic_slice(rand_idx_local,[j_idx*batch_size],[batch_size])\n",
    "\n",
    "    val,g = grad_render3([p[0]*SCALE_MUL_FACTOR,p[1]/SCALE_MUL_FACTOR,p[2],p[3]],all_rays[idx],invF,vecM*poses,all_sils[idx],fwv_flow[idx],bwv_flow[idx],all_colors[idx])   \n",
    "    updates, opt_state = optimizer.update(g, opt_state,p)\n",
    "    p = optax.apply_updates(p, updates)\n",
    "    return val, opt_state, p \n",
    "jax_iter = jax.jit(inner_iter)\n",
    "done = False\n",
    "for i in outer_loop:\n",
    "    np.random.shuffle(rand_idx)\n",
    "    rand_idx_jnp = jnp.array(rand_idx)\n",
    "\n",
    "    for j in tqdm(range(Niter_epoch), desc=\" iteration\", position=1, leave=False):\n",
    "        opt_configs.append(list(params))\n",
    "        val,opt_state,params = jax_iter(j,rand_idx_jnp,opt_state,params)\n",
    "        val = float(val)\n",
    "        losses.append(val)\n",
    "        if np.isnan(val):\n",
    "            raise\n",
    "\n",
    "        if adjust_lr.add(val):\n",
    "            done = True\n",
    "            break\n",
    "        outer_loop.set_description(\" loss {:.3f}\".format(val))\n",
    "    if done:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_mean, final_prec, final_weight_log,final_color = params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_depths = []\n",
    "result_alphas = []\n",
    "results_colors = []\n",
    "\n",
    "for i in range(len(poses)):\n",
    "    pixel_list[:,3] = i\n",
    "    res_img,est_alpha,_,w = render_jit(final_mean, final_prec, final_weight_log,pixel_list,invF,poses)\n",
    "    est_color = np.array(w.T @ (jnp.tanh(final_color)*0.5+0.5))**(2.2)\n",
    "\n",
    "    res_imgA = np.array(res_img)\n",
    "    est_alpha = np.array(est_alpha)\n",
    "    res_imgA[est_alpha < 0.5] = np.nan\n",
    "    est_color[est_alpha < 0.5] = np.nan\n",
    "\n",
    "    result_depths.append(res_imgA.reshape((PY,PX)))\n",
    "    result_alphas.append(est_alpha.reshape((PY,PX)))\n",
    "    results_colors.append(est_color.reshape((PY,PX,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1,3,1)\n",
    "plt.imshow(result_alphas[-1])\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(result_depths[-1])\n",
    "plt.axis('off')\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(est_color.reshape((PY,PX,3)),interpolation='nearest')\n",
    "plt.axis('off')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import trim_mean\n",
    "errs = []\n",
    "d1f = np.hstack([_.ravel() for _ in  true_depths]).ravel()\n",
    "d2f = np.hstack([_.ravel() for _ in result_depths]).ravel()\n",
    "\n",
    "mask = (all_sils !=0 ) & (~np.isnan(d1f)) & (~np.isnan(d2f)) & (d1f !=0) \n",
    "\n",
    "trim_mean(abs(d1f[mask]-d2f[mask]),0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_grid(masks,rows=3,cols=5,rgb=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_frame = len(poses)\n",
    "FWD_BCK_TIMES = 4\n",
    "THRESH_IDX = np.where(np.array(losses)/min(losses) < 1.02)[0][0]\n",
    "USE_FIRST_N_FRAC = THRESH_IDX/len(losses)\n",
    "N_FRAMES = max_frame*FWD_BCK_TIMES\n",
    "opt_to_use = np.round(np.linspace(0,int(np.floor(len(opt_configs)*USE_FIRST_N_FRAC-1)),N_FRAMES)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESH_IDX/len(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses[:THRESH_IDX])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(output_folder):\n",
    "    import shutil\n",
    "    shutil.rmtree(output_folder)\n",
    "os.makedirs(output_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_idxs = []\n",
    "frame_list = list(range(max_frame))\n",
    "for i in range(FWD_BCK_TIMES):\n",
    "    if (i % 2) == 0:\n",
    "        frame_idxs += frame_list\n",
    "    else:\n",
    "        frame_idxs += frame_list[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_res_alpha = []\n",
    "full_res_depth = []\n",
    "full_res_color = []\n",
    "\n",
    "for r_idx,c_idx in zip(frame_idxs,opt_to_use):\n",
    "    p = opt_configs[c_idx]\n",
    "\n",
    "    pixel_list[:,3] = r_idx\n",
    "    est_depth,est_alpha,_,w = render_jit(p[0],p[1],p[2],pixel_list,invF,poses)\n",
    "    est_color = np.array(w.T @ (jnp.tanh(p[3])*0.5+0.5))**(2.2)\n",
    "\n",
    "    est_alpha = np.array(est_alpha)\n",
    "    est_depth = np.array(est_depth)\n",
    "    est_depth[est_alpha < 0.5] = np.nan\n",
    "    est_color[est_alpha < 0.5] = np.nan\n",
    "\n",
    "    full_res_alpha.append(est_alpha.reshape((PY,PX)))\n",
    "    full_res_depth.append(est_depth.reshape((PY,PX)))\n",
    "    full_res_color.append(est_color.reshape((PY,PX,3)))\n",
    "\n",
    "    print('.',end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(output_folder):\n",
    "    import shutil\n",
    "    shutil.rmtree(output_folder)\n",
    "os.makedirs(output_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vecr = np.hstack([_.ravel() for _ in full_res_depth])\n",
    "vecr = vecr[~np.isnan(vecr)]\n",
    "vmin = np.percentile(vecr,5)\n",
    "vmax = np.percentile(vecr,95)\n",
    "vscale = vmax-vmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "start_f = 0\n",
    "avg_size = np.array([PX,PY])\n",
    "fsize = irc(96/4)\n",
    "\n",
    "font = ImageFont.truetype('Roboto-Regular.ttf', size=irc(avg_size[0]/8))\n",
    "cmap = matplotlib.cm.get_cmap('viridis')\n",
    "cmap2 = matplotlib.cm.get_cmap('magma')\n",
    "\n",
    "for i,mask_res in enumerate(full_res_alpha):\n",
    "    r_idx = frame_idxs[i]\n",
    "    #img1 = ground_images[r_idx]/255.0*np.clip(full_masks[r_idx] > .1,0.3,1)[:,:,None]\n",
    "    #img2 = ground_images[r_idx]*np.clip((mask_res)**0.4,0.05,1)[:,:,None]\n",
    "    img2 = full_res_color[i]#np.tile(mask_res[:,:,None],(1,1,3))\n",
    "    img_gt_mask = np.tile(masks[r_idx][:,:,None],(1,1,3))\n",
    "\n",
    "    true_alpha = masks[r_idx]\n",
    "\n",
    "    est_alpha = jnp.clip(mask_res,1e-6,1-1e-6)\n",
    "    mask_loss = - ((true_alpha * jnp.log(est_alpha)) + (1-true_alpha)*jnp.log(1-est_alpha))\n",
    "    loss_viz = cmap2(0.25*mask_loss)[:,:,:3]\n",
    "\n",
    "    depth = cmap((full_res_depth[i]-vmin)/vscale)[:,:,:3]\n",
    "    img2 = np.concatenate((images[r_idx]/255.0,img_gt_mask,loss_viz,img2, depth), axis=1)\n",
    "    int_img = np.round(img2*255).astype(np.uint8)\n",
    "    pil_img = Image.fromarray(int_img)\n",
    "    d1 = ImageDraw.Draw(pil_img)\n",
    "    d1.text((avg_size[0]*1.1, irc(fsize*0.1)), \"Iteration: {:3d}\\nEpoch: {:.1f}\".format(opt_to_use[i],opt_to_use[i]/Niter_epoch), ha='center',font=font,fill=(180, 180, 180))\n",
    "    d1.text((avg_size[0]*1.3, irc(avg_size[1]-fsize*1.5)), \"Target Mask\", font=font,fill=(255, 255, 255),ha='center')\n",
    "    d1.text((avg_size[0]*2.4, irc(avg_size[1]-fsize*1.5)), \"Loss\", font=font,fill=(255, 255, 255),ha='center',align='center')\n",
    "    d1.text((avg_size[0]*3.3, irc(avg_size[1]-fsize*2.5)), \"Estimated\\nColor\", font=font,fill=(255, 255, 255),ha='center',align='center')\n",
    "    d1.text((avg_size[0]*4.3, irc(avg_size[1]-fsize*2.5)), \"Estimated\\nDepth\", font=font,fill=(255, 255, 255),ha='center',align='center')\n",
    "\n",
    "    img3 = np.array(pil_img)\n",
    "    \n",
    "    sio.imsave('{}/{:03d}.jpg'.format(output_folder,i),img3,quality=95)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(avg_size[0]*1.3, irc(avg_size[1]-fsize*1.5)),avg_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,8))\n",
    "plt.imshow(img3)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "if os.path.exists('{}.mp4'.format(output_folder)):\n",
    "    os.remove('{}.mp4'.format(output_folder))\n",
    "subprocess.call(' '.join(['/usr/bin/ffmpeg',\n",
    "                 '-framerate','60',\n",
    "                 '-i','{}/%03d.jpg'.format(output_folder),\n",
    "                 '-vf','\\\"pad=ceil(iw/2)*2:ceil(ih/2)*2\\\"',\n",
    "                 '-c:v','h264',\n",
    "                 '-pix_fmt','yuv420p',\n",
    "                 '{}.mp4'.format(output_folder)]),shell=True)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
