{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qkX7DiM6rmeM"
   },
   "source": [
    "# Pose Estimation\n",
    "Compare to PyTorch3D `Camera position optimization` sample. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import trimesh\n",
    "import pyrender\n",
    "import transforms3d\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "class QuasiRandom():\n",
    "    def __init__(self,dim=1,seed=None):\n",
    "        self.dim = dim\n",
    "        self.x = np.random.rand(dim) if seed is None else seed\n",
    "        root_sys = [1] +[0 for i in range(dim-1)] + [-1,-1]\n",
    "        self.const = sorted(np.roots(root_sys))[-1].real\n",
    "        self.phi = np.array([1/(self.const)**(i+1) for i in range(dim)])\n",
    "    def generate(self,n_points=1):\n",
    "        res = np.zeros((n_points,self.dim))\n",
    "        for i in range(n_points):\n",
    "            res[i] = self.x = (self.x+self.phi)\n",
    "        return np.squeeze(res%1)\n",
    "    \n",
    "mesh_file = 'data/cow.obj'\n",
    "\n",
    "mesh_tri = trimesh.load(mesh_file)\n",
    "\n",
    "# seems sane to fetch/estimate scale\n",
    "shape_scale = float(mesh_tri.vertices.std(0).mean())*3\n",
    "center = np.array(mesh_tri.vertices.mean(0))\n",
    "t_model_scale = np.ptp(mesh_tri.vertices,0).mean()\n",
    "\n",
    "print('model is {:.2f}x the size of the cow'.format(shape_scale/1.18))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = (64,64)\n",
    "vfov_degrees = 45\n",
    "focal_length = 0.5*image_size[0]/np.tan((np.pi/180.0)*vfov_degrees/2)\n",
    "cx = (image_size[1]-1)/2\n",
    "cy = (image_size[0]-1)/2\n",
    "rand_quat = QuasiRandom(dim=4,seed=0).generate(1)\n",
    "rand_quat = rand_quat/np.linalg.norm(rand_quat)\n",
    "\n",
    "mesh = pyrender.Mesh.from_trimesh(mesh_tri)\n",
    "\n",
    "scene = pyrender.Scene()\n",
    "scene.add(mesh)\n",
    "\n",
    "\n",
    "R = transforms3d.quaternions.quat2mat(rand_quat)\n",
    "loc = np.array([0,0,3*shape_scale]) @ R + center\n",
    "pose = np.vstack([np.vstack([R,loc]).T,np.array([0,0,0,1])])\n",
    "\n",
    "light = pyrender.SpotLight(color=np.ones(3), intensity=50.0,\n",
    "                            innerConeAngle=np.pi/16.0,\n",
    "                            outerConeAngle=np.pi/6.0)\n",
    "scene.add(light, pose=pose)\n",
    "\n",
    "camera = pyrender.IntrinsicsCamera(focal_length,focal_length,cx,cy,znear=0.1*shape_scale,zfar=100*shape_scale)\n",
    "scene.add(camera,pose=pose)\n",
    "\n",
    "r = pyrender.OffscreenRenderer(image_size[1],image_size[0])\n",
    "color, target_depth = r.render(scene)\n",
    "target_depth[target_depth ==0] = np.nan\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(color)\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(target_depth)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Fuzzy Metaball renderer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"] = \"false\"\n",
    "\n",
    "import jax\n",
    "#jax.config.update('jax_platform_name', 'cpu')\n",
    "\n",
    "import jax.numpy as jnp\n",
    "import fm_render\n",
    "\n",
    "# volume usually False since color optimization implies surface samples\n",
    "# And code defaults towards that sort of usage now\n",
    "show_volume = False\n",
    "\n",
    "NUM_MIXTURE = 40\n",
    "beta2 = 21.4\n",
    "beta3 = 2.66\n",
    "\n",
    "gmm_init_scale = 80\n",
    "\n",
    "render_jit = jax.jit(fm_render.render_func_quat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import trimesh\n",
    "import sklearn.mixture\n",
    "if show_volume:\n",
    "    pts = trimesh.sample.volume_mesh(mesh_tri,10000)\n",
    "else:\n",
    "    pts = trimesh.sample.sample_surface_even(mesh_tri,10000)[0]\n",
    "gmm = sklearn.mixture.GaussianMixture(NUM_MIXTURE)\n",
    "gmm.fit(pts)\n",
    "weights_log = np.log( gmm.weights_) + np.log(gmm_init_scale)\n",
    "mean = gmm.means_\n",
    "prec = gmm.precisions_cholesky_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "height, width = image_size\n",
    "K = np.array([[focal_length, 0, cx],[0,focal_length,cy],[0,0,1]])\n",
    "pixel_list = (np.array(np.meshgrid(np.arange(width),height-np.arange(height)-1,[0]))[:,:,:,0]).reshape((3,-1)).T\n",
    "camera_rays = (pixel_list - K[:,2])/np.diag(K)\n",
    "camera_rays[:,-1] = -1\n",
    "\n",
    "trans_true = loc\n",
    "quat_true = rand_quat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add noise to pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    t_err_cap = 0.5\n",
    "    rad_eps = (np.pi/180.0)*90 # range. so 90 is -45 to +45\n",
    "\n",
    "    t_err_vec = np.random.randn(3)\n",
    "    t_err_vec = t_err_vec/np.linalg.norm(t_err_vec)\n",
    "    t_err_mag = np.random.rand()\n",
    "\n",
    "    trans_offset = t_err_cap*t_err_mag*t_err_vec*t_model_scale\n",
    "    trans_shift = trans_true - trans_offset\n",
    "\n",
    "    angles = np.random.randn(3)\n",
    "    angles = angles/np.linalg.norm(angles)\n",
    "    angle_mag = (np.random.rand()-0.5)*rad_eps\n",
    "    R_I = transforms3d.quaternions.quat2mat(quat_true).T\n",
    "    R_R = transforms3d.axangles.axangle2mat(angles,angle_mag)\n",
    "    R_C =  R_R @ R_I\n",
    "\n",
    "    quat_init = transforms3d.quaternions.mat2quat(R_C.T)\n",
    "    trans_init = R_R@trans_shift\n",
    "\n",
    "    rand_rot = abs(angle_mag*(180.0/np.pi))\n",
    "    rand_trans = 100*(t_err_mag*t_err_cap)\n",
    "    init_pose_err = np.sqrt(rand_rot*rand_trans)\n",
    "    if rand_trans >30 and rand_rot >30:\n",
    "        print('pose error of {:.1f}, random rotation of {:.1f} degrees and translation of {:.1f}%'.format(init_pose_err,rand_rot,rand_trans))\n",
    "        break\n",
    "#axangl_init = axangl_true.copy()\n",
    "#trans_init = trans_true.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_normals(camera_rays, depth_py_px,image_size):\n",
    "    nan_depth = depth_py_px.ravel()\n",
    "    PY,PX=image_size\n",
    "    #nan_depth = jnp.nan_to_num(depth_py_px.ravel(),nan=1e-9)\n",
    "\n",
    "    dpt = jnp.array( camera_rays.reshape((-1,3)) * nan_depth[:,None] )\n",
    "    dpt = dpt.reshape((PY,PX,3))\n",
    "    ydiff = dpt - jnp.roll(dpt,1,0)\n",
    "    xdiff = dpt - jnp.roll(dpt,1,1)\n",
    "    ydiff = jnp.nan_to_num(ydiff,nan=1e-9) # new\n",
    "    xdiff = jnp.nan_to_num(xdiff,nan=1e-9) # new \n",
    "\n",
    "    ddiff = jnp.cross(xdiff.reshape((-1,3)),ydiff.reshape((-1,3)),)\n",
    "    nan_ddiff = jnp.nan_to_num(ddiff,nan=0)\n",
    "    norms = nan_ddiff/(1e-20+jnp.linalg.norm(nan_ddiff,axis=1,keepdims=True))\n",
    "\n",
    "    return norms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solve for camera pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_func(est_depth,est_alpha,true_depth):\n",
    "    cond = jnp.isnan(est_depth) | jnp.isnan(true_depth)\n",
    "    #err = (est_depth - true_depth)/jnp.nan_to_num(true_depth,nan=1)\n",
    "    err = (est_depth - true_depth)/jnp.nanmean(true_depth)\n",
    "\n",
    "    depth_loss =  abs(jnp.where(cond,0,err)).mean()\n",
    "\n",
    "    true_alpha = ~jnp.isnan(true_depth)\n",
    "    est_alpha = jnp.clip(est_alpha,1e-7,1-1e-7)\n",
    "    mask_loss = -((true_alpha * jnp.log(est_alpha)) + (~true_alpha)*jnp.log(1-est_alpha))\n",
    "\n",
    "    term1 = depth_loss.mean()\n",
    "    term2 = mask_loss.mean()\n",
    "    return 50*term1 + term2\n",
    "\n",
    "def objective(params,means,prec,weights_log,camera_rays,beta2,beta3,depth):\n",
    "    mrp,trans= params\n",
    "    render_res = render_jit(means,prec,weights_log,camera_rays,mrp,trans,beta2,beta3)\n",
    "    return error_func(render_res[0],render_res[1],depth)\n",
    "\n",
    "def objective_simple(params,means,prec,weights_log,camera_rays,beta2,beta3,depth):\n",
    "    mrp = jnp.array(params[:3])\n",
    "    trans = jnp.array(params[3:])\n",
    "    render_res = render_jit(means,prec,weights_log,camera_rays,mrp,trans,beta2,beta3)\n",
    "    return error_func(render_res[0],render_res[1],depth)\n",
    "grad_render3 = jax.jit(jax.value_and_grad(objective))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax.example_libraries import optimizers\n",
    "from util import DegradeLR\n",
    "# Number of optimization steps\n",
    "# typically only needs a few hundred\n",
    "# and early exits\n",
    "Niter = 2000\n",
    "\n",
    "loop = tqdm(range(Niter))\n",
    "\n",
    "# babysit learning rates\n",
    "adjust_lr = DegradeLR(3e-4,0.1,50,10,-1e-4)\n",
    "opt_init, opt_update, opt_params = optimizers.momentum(adjust_lr.step_func,0.95)\n",
    "\n",
    "# to test scale invariance\n",
    "HUHSCALE = 1\n",
    "# should get same result even if world scale changes\n",
    "\n",
    "tmp = [quat_init,HUHSCALE*trans_init]\n",
    "opt_state = opt_init(tmp)\n",
    "\n",
    "losses = []\n",
    "jax_tdepth = jnp.array(target_depth.ravel())\n",
    "\n",
    "for i in loop:\n",
    "    p = opt_params(opt_state)\n",
    "\n",
    "    val,g = grad_render3(p,HUHSCALE*mean,prec/HUHSCALE,weights_log,camera_rays,beta2/(HUHSCALE*shape_scale),beta3,HUHSCALE*jax_tdepth)\n",
    "    \n",
    "    S = jnp.linalg.norm(p[1])\n",
    "    S2 = S*S\n",
    "\n",
    "    g1 = g[0]\n",
    "    g2 = g[1]*S2\n",
    "\n",
    "    opt_state = opt_update(i, [g1,g2], opt_state)\n",
    "\n",
    "    val = float(val)\n",
    "    losses.append(val)\n",
    "    if adjust_lr.add(val):\n",
    "        break\n",
    "    # Print the losses\n",
    "    loop.set_description(\"total_loss = %.3f\" % val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mrp_final, trans_final = opt_params(opt_state)\n",
    "trans_final = trans_final/HUHSCALE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2nd order is also possible\n",
    "if False:\n",
    "    from jax.scipy.optimize import minimize\n",
    "    res = minimize(objective_simple,jnp.hstack([mrp_init,trans_init]),method='BFGS',args=(mean,prec,weight_log,camera_rays,beta2,beta3,beta4,beta5,jax_tdepth,))\n",
    "    mrp_final = res.x[:3]\n",
    "    trans_final = res.x[3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('convergence plot')\n",
    "plt.plot(losses,marker='.',lw=0,ms=5,alpha=0.5)\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('log loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quat_final, trans_final = opt_params(opt_state)\n",
    "trans_final = trans_final/HUHSCALE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmin,vmax = np.nanmin(target_depth),np.nanmax(target_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(2,3,1)\n",
    "plt.imshow(color)\n",
    "plt.title('image')\n",
    "plt.axis('off')\n",
    "plt.subplot(2,3,4)\n",
    "est_depth_true, est_alpha_true, _, _ = render_jit(mean,prec,weights_log,camera_rays,quat_true,trans_true,beta2/shape_scale,beta3)\n",
    "est_depth_true = np.array(est_depth_true)\n",
    "est_depth_true[est_alpha_true < 0.5] = np.nan\n",
    "plt.imshow(est_depth_true.reshape(image_size),vmin=vmin,vmax=vmax)\n",
    "plt.title('true pose')\n",
    "plt.axis('off')\n",
    "est_depth_init, est_alpha, _, _ = render_jit(mean,prec,weights_log,camera_rays,quat_init,trans_init,beta2/shape_scale,beta3)\n",
    "est_depth_init = np.array(est_depth_init)\n",
    "est_depth_init[est_alpha < 0.5] = np.nan\n",
    "plt.subplot(2,3,2)\n",
    "plt.imshow(est_alpha.reshape(image_size),cmap='Greys')\n",
    "plt.title('init FM alpha')\n",
    "plt.axis('off')\n",
    "plt.subplot(2,3,5)\n",
    "plt.imshow(est_depth_init.reshape(image_size),vmin=vmin,vmax=vmax)\n",
    "plt.title('init FM depth')\n",
    "plt.axis('off')\n",
    "est_depth,  est_alpha, _, _ = render_jit(mean,prec,weights_log,camera_rays,quat_final,trans_final,beta2/shape_scale,beta3)\n",
    "est_depth = np.array(est_depth)\n",
    "est_depth[est_alpha < 0.5] = np.nan\n",
    "plt.subplot(2,3,3)\n",
    "plt.imshow(est_alpha.reshape(image_size),cmap='Greys')\n",
    "plt.title('final FM alpha')\n",
    "plt.axis('off')\n",
    "plt.subplot(2,3,6)\n",
    "plt.imshow(est_depth.reshape(image_size),vmin=vmin,vmax=vmax)\n",
    "plt.title('final FM depth')\n",
    "plt.axis('off')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = quat_true/np.linalg.norm(quat_true)\n",
    "q2 = quat_final/np.linalg.norm(quat_final)\n",
    "e1 = np.arccos(np.clip((q1 * q2).sum(),-1,1))\n",
    "e2 = np.arccos(np.clip((-q1 * q2).sum(),-1,1))\n",
    "rot_err = float((180.0/np.pi)*2*min(e1,e2))\n",
    "\n",
    "R1 = np.array(transforms3d.quaternions.quat2mat(q1))\n",
    "R2 = np.array(transforms3d.quaternions.quat2mat(q2))\n",
    "t_norm = np.linalg.norm(R1.T@np.array(trans_true)-R2.T@np.array(trans_final))\n",
    "trans_err = 100*t_norm/t_model_scale\n",
    "\n",
    "pose_err = np.sqrt(rot_err*trans_err)\n",
    "print('init. pose error of {:04.1f} with rot. of {:04.1f} deg and trans. of {:04.1f}%'.format(init_pose_err,rand_rot,rand_trans))\n",
    "print('final pose error of {:04.1f} with rot. of {:04.1f} deg and trans. of {:04.1f}%'.format(pose_err,rot_err,trans_err))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
